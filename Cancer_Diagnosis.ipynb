{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancerous Gene Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This problem statement was taken from https://www.kaggle.com/c/msk-redefining-cancer-treatment/overview\n",
    "\n",
    "* Download the datasets **'training_text'** & **'training_variants'** from https://www.kaggle.com/c/msk-redefining-cancer-treatment/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of the code below:**\n",
    "1. Importing dependencies and acquiring data\n",
    "2. Performing EDA and Data Pre-processing\n",
    "3. Splitting the dataset into train, cross-validation and test sets\n",
    "4. Performing hyper-parameter tuning over the cross-validation set for each model namely, Logistic Regression, Linear SVM and Random Forest.\n",
    "\n",
    "\n",
    "* *The metric used to evaluate and compare the results of the models was **log-loss**.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "import pdb\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3321, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  Class\n",
       "0   0  FAM58A  Truncating Mutations      1\n",
       "1   1     CBL                 W802*      2\n",
       "2   2     CBL                 Q249E      2\n",
       "3   3     CBL                 N454D      3\n",
       "4   4     CBL                 L399V      4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('training_variants')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  [1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print('Number of classes: ',data.Class.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the gene-variation pairs will get classified into 9 different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x21f4e030cc0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 756x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.catplot(x=\"Class\", kind=\"count\", palette=\"ch:.25\", data=data, height = 7, aspect = 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since the distribution of classes is skewed, we have to maintain this disb. throughout the train, cv and test sets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3321, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Text\n",
       "0   0  Cyclin-dependent kinases (CDKs) regulate a var...\n",
       "1   1   Abstract Background  Non-small cell lung canc...\n",
       "2   2   Abstract Background  Non-small cell lung canc...\n",
       "3   3  Recent evidence has demonstrated that acquired...\n",
       "4   4  Oncogenic mutations in the monomeric Casitas B..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Looking at the data we see that ID and Text are not seperated by commas, but rather '||' wiz. a double pipe delimited file\n",
    "as mentioned in the kaggle page, which we have to seperate over to avoid the parse error. Also, the first line is the \n",
    "column names but they're not assigned correctly. Hence, we need to skip that row and assign the values normally.\n",
    "\n",
    "referenced the parsing from https://stackoverflow.com/questions/58707332/parsing-a-double-pipe-delimited-file-in-python\n",
    "'''\n",
    "\n",
    "text_data = pd.read_csv('training_text',sep='\\|\\|', names=['ID','Text'], skiprows=1)\n",
    "\n",
    "print(text_data.shape)\n",
    "text_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading stop words from nltk library\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# referenced from https://stackoverflow.com/questions/23996118/replace-special-characters-in-a-string-python\n",
    "# and https://pythonexamples.org/python-replace-multiple-spaces-with-single-space-in-text-file/\n",
    "\n",
    "def clean_text(corpus):\n",
    "        \n",
    "    if type(corpus) is not int:\n",
    "        a = \"\"\n",
    "        text = re.sub('[^a-zA-Z0-9\\n]',' ',corpus)\n",
    "        text = re.sub('\\s+',' ',corpus)\n",
    "        text = text.lower()\n",
    "        \n",
    "        for word in text.split():\n",
    "            \n",
    "            if word in stop_words:\n",
    "                a += ''\n",
    "            else:\n",
    "                a += word + \" \"\n",
    "        \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text NA for ID:1109\n",
      "Text NA for ID:1277\n",
      "Text NA for ID:1407\n",
      "Text NA for ID:1639\n",
      "Text NA for ID:2755\n"
     ]
    }
   ],
   "source": [
    "ids = text_data['ID'].copy()\n",
    "index = 0\n",
    "for i in text_data.Text:\n",
    "    #pdb.set_trace()\n",
    "    if type(i) is str:\n",
    "        x = clean_text(i)\n",
    "        text_data['Text'][index] = x\n",
    "    else:\n",
    "        b = ids[index]\n",
    "        print(f'Text NA for ID:{b}')\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cyclin-dependent kinases (cdks) regulate varie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>abstract background non-small cell lung cancer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>abstract background non-small cell lung cancer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>recent evidence demonstrated acquired uniparen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>oncogenic mutations monomeric casitas b-lineag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Text\n",
       "0   0  cyclin-dependent kinases (cdks) regulate varie...\n",
       "1   1  abstract background non-small cell lung cancer...\n",
       "2   2  abstract background non-small cell lung cancer...\n",
       "3   3  recent evidence demonstrated acquired uniparen...\n",
       "4   4  oncogenic mutations monomeric casitas b-lineag..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>cyclin-dependent kinases (cdks) regulate varie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract background non-small cell lung cancer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract background non-small cell lung cancer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "      <td>recent evidence demonstrated acquired uniparen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "      <td>oncogenic mutations monomeric casitas b-lineag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  Class  \\\n",
       "0   0  FAM58A  Truncating Mutations      1   \n",
       "1   1     CBL                 W802*      2   \n",
       "2   2     CBL                 Q249E      2   \n",
       "3   3     CBL                 N454D      3   \n",
       "4   4     CBL                 L399V      4   \n",
       "\n",
       "                                                Text  \n",
       "0  cyclin-dependent kinases (cdks) regulate varie...  \n",
       "1  abstract background non-small cell lung cancer...  \n",
       "2  abstract background non-small cell lung cancer...  \n",
       "3  recent evidence demonstrated acquired uniparen...  \n",
       "4  oncogenic mutations monomeric casitas b-lineag...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging both gene_variations and text data based on ID\n",
    "result = pd.merge(data, text_data, on='ID', how='left')\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Gene         0\n",
       "Variation    0\n",
       "Class        0\n",
       "Text         5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1109</td>\n",
       "      <td>FANCA</td>\n",
       "      <td>S1088F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>1277</td>\n",
       "      <td>ARID5B</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>1407</td>\n",
       "      <td>FGFR3</td>\n",
       "      <td>K508M</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>1639</td>\n",
       "      <td>FLT1</td>\n",
       "      <td>Amplification</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>2755</td>\n",
       "      <td>BRAF</td>\n",
       "      <td>G596C</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID    Gene             Variation  Class Text\n",
       "1109  1109   FANCA                S1088F      1  NaN\n",
       "1277  1277  ARID5B  Truncating Mutations      1  NaN\n",
       "1407  1407   FGFR3                 K508M      6  NaN\n",
       "1639  1639    FLT1         Amplification      6  NaN\n",
       "2755  2755    BRAF                 G596C      7  NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = result[result.isnull().any(axis=1)].copy()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gene\n",
       "BRCA1     264\n",
       "TP53      163\n",
       "EGFR      141\n",
       "PTEN      126\n",
       "BRCA2     125\n",
       "KIT        99\n",
       "BRAF       93\n",
       "ERBB2      69\n",
       "ALK        69\n",
       "PDGFRA     60\n",
       "         ... \n",
       "PPM1D       1\n",
       "PMS1        1\n",
       "PIK3R3      1\n",
       "PAX8        1\n",
       "ERRFI1      1\n",
       "PAK1        1\n",
       "FAM58A      1\n",
       "FANCC       1\n",
       "FGF19       1\n",
       "KLF4        1\n",
       "Name: Gene, Length: 264, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.min_rows = 20\n",
    "b = result.groupby('Gene')['Gene'].count()\n",
    "b\n",
    "b.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of the pair of FANCA and S1088F is 1\n",
      "The count of the pair of ARID5B and Truncating Mutations is 1\n",
      "The count of the pair of FGFR3 and K508M is 1\n",
      "The count of the pair of FLT1 and Amplification is 1\n",
      "The count of the pair of BRAF and G596C is 1\n"
     ]
    }
   ],
   "source": [
    "# referenced from https://www.geeksforgeeks.org/iterating-over-rows-and-columns-in-pandas-dataframe/\n",
    "\n",
    "for i,j in a.iterrows():\n",
    "    count = 0\n",
    "    for k,v in result.iterrows():\n",
    "        #pdb.set_trace()\n",
    "        if (j['Gene'] == v['Gene']) & (j['Variation'] == v['Variation']):\n",
    "            count+=1\n",
    "    if count >= 1:\n",
    "        print('The count of the pair of {} and {} is {}'.format(j['Gene'],j['Variation'], count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We see that the above pairs having no supporting text are only present once throughout the dataset. If we remove these rows then we could loose their classification (especially for class 6 as they are less in count throughout the dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Instead of removing these gene-variation pairs, we can just replace the NaN with the gene and variation name in the respective 'Text' field.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[result['Text'].isnull(),'Text'] = result['Gene'] +' '+result['Variation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>2755</td>\n",
       "      <td>BRAF</td>\n",
       "      <td>G596C</td>\n",
       "      <td>7</td>\n",
       "      <td>BRAF G596C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Gene Variation  Class        Text\n",
       "2755  2755  BRAF     G596C      7  BRAF G596C"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result['ID']==2755]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3321"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Since, we're to do onehot encoding for the features, it is better that we replace the spaces in gene and variation \n",
    "feature with an underscore\n",
    "\n",
    "'''\n",
    "\n",
    "strat_disb = result['Class'].values\n",
    "result.Gene = result.Gene.str.replace('\\s+', '_')\n",
    "result.Variation = result.Variation.str.replace('\\s+', '_')\n",
    "\n",
    "# using stratify will help us here to maintain the same distribution of class labels in our subsets as well\n",
    "\n",
    "X_train, x_test, train_y, y_test = train_test_split(result, strat_disb, stratify=strat_disb, test_size=0.2, random_state=60)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(X_train, train_y, stratify=train_y, test_size=0.2, random_state=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurization of the text feature using one hot encoding (tfidf) \n",
    "# limiting the featurization to those words which occur atleast 3 times in the corpus\n",
    "\n",
    "text_tfidf = TfidfVectorizer(min_df=3)\n",
    "text_tfidf.fit(x_train['Text'])\n",
    "train_text = text_tfidf.transform(x_train['Text'])\n",
    "train_text = normalize(train_text, axis=0)\n",
    "\n",
    "# using the same vectorizer that was trained on train data\n",
    "\n",
    "cv_text = text_tfidf.transform(x_cv['Text'])\n",
    "cv_text = normalize(cv_text, axis=0)\n",
    "\n",
    "test_text = text_tfidf.transform(x_test['Text'])\n",
    "test_text = normalize(test_text, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurization of the gene and variation features using one hot encoding \n",
    "\n",
    "gene_ohe = CountVectorizer()\n",
    "train_gene = gene_ohe.fit_transform(x_train['Gene'])\n",
    "train_gene = normalize(train_gene, axis=0)\n",
    "\n",
    "cv_gene = gene_ohe.transform(x_cv['Gene'])\n",
    "cv_gene = normalize(cv_gene, axis=0)\n",
    "\n",
    "test_gene = gene_ohe.transform(x_test['Gene'])\n",
    "test_gene = normalize(test_gene, axis=0)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "variation_ohe = CountVectorizer()\n",
    "train_variation = variation_ohe.fit_transform(x_train['Variation'])\n",
    "train_variation = normalize(train_variation, axis=0)\n",
    "\n",
    "cv_variation = variation_ohe.transform(x_cv['Variation'])\n",
    "cv_variation = normalize(cv_variation, axis=0)\n",
    "\n",
    "test_variation = variation_ohe.transform(x_test['Variation'])\n",
    "test_variation = normalize(test_variation, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2124, 233)\n",
      "(2124, 1974)\n",
      "(2124, 56489)\n"
     ]
    }
   ],
   "source": [
    "print(train_gene.shape)\n",
    "print(train_variation.shape)\n",
    "print(train_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_final = hstack((train_gene, train_variation, train_text)).tocsr()\n",
    "y_train_final = np.array(list(x_train['Class']))\n",
    "\n",
    "x_cv_final = hstack((cv_gene, cv_variation, cv_text)).tocsr()\n",
    "y_cv_final = np.array(list(x_cv['Class']))\n",
    "\n",
    "x_test_final = hstack((test_gene, test_variation, test_text)).tocsr()\n",
    "y_test_final = np.array(list(x_test['Class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2124, 58696)\n",
      "(665, 58696)\n",
      "(532, 58696)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_final.shape)\n",
    "print(x_test_final.shape)\n",
    "print(x_cv_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 1e-05\n",
      "CV log Loss : 1.2554856827616867\n",
      "For alpha = 0.0001\n",
      "CV log Loss : 1.1013905238914352\n",
      "For alpha = 0.001\n",
      "CV log Loss : 1.165879328943427\n",
      "For alpha = 0.01\n",
      "CV log Loss : 1.2518909495939732\n",
      "For alpha = 0.1\n",
      "CV log Loss : 1.4005614924980676\n",
      "For alpha = 1\n",
      "CV log Loss : 1.560547384571933\n",
      "For alpha = 10\n",
      "CV log Loss : 1.5931389097786206\n"
     ]
    }
   ],
   "source": [
    "# Using SGD Classifier with loss argument as log loss so that it functions as a Logistic Regression\n",
    "# Using 'balanced' class_weight here to maintain the ratio of the classes\n",
    "'''\n",
    "Since we do not want a blackbox model and want to classify the mutations with utmost certainty we use CalibratedClassifierCV. \n",
    "referenced from https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/\n",
    "''' \n",
    "alpha = [10 ** x for x in range(-5, 2)]\n",
    "list_log_loss = []\n",
    "for i in alpha:\n",
    "    print(\"For alpha =\", i)\n",
    "    logistic = SGDClassifier(class_weight='balanced', alpha=i, penalty='l2', loss='log', random_state=60)\n",
    "    logistic.fit(x_train_final, y_train_final)\n",
    "    prob_logistic = CalibratedClassifierCV(logistic)\n",
    "    prob_logistic.fit(x_train_final, y_train_final)\n",
    "    prob_x_cv = prob_logistic.predict_proba(x_cv_final)\n",
    "    list_log_loss.append(log_loss(y_cv_final, prob_x_cv, labels=logistic.classes_)) \n",
    "    \n",
    "    # to avoid rounding error while multiplying probabilites I used log-probability estimates\n",
    "    print(\"CV log Loss :\",log_loss(y_cv_final, prob_x_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling with the best value of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the value of best alpha = 0.0001\n",
      "\n",
      "Train log loss : 0.5428493957402157\n",
      "Cross Validation log loss : 1.1013905238914352\n",
      "Test log loss : 1.069329304971553\n"
     ]
    }
   ],
   "source": [
    "best_alpha = np.argmin(list_log_loss)\n",
    "logistic = SGDClassifier(class_weight='balanced', alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=60)\n",
    "logistic.fit(x_train_final, y_train_final)\n",
    "prob_logistic = CalibratedClassifierCV(logistic, method=\"sigmoid\")\n",
    "prob_logistic.fit(x_train_final, y_train_final)\n",
    "\n",
    "print('For the value of best alpha =', alpha[best_alpha])\n",
    "prob_final_train = prob_logistic.predict_proba(x_train_final) \n",
    "print('\\nTrain log loss :',log_loss(y_train_final, prob_final_train, labels=logistic.classes_))\n",
    "prob_final_cv = prob_logistic.predict_proba(x_cv_final)\n",
    "print('Cross Validation log loss :',log_loss(y_cv_final, prob_final_cv, labels=logistic.classes_))\n",
    "prob_final_test = prob_logistic.predict_proba(x_test_final)\n",
    "print('Test log loss :',log_loss(y_test_final, prob_final_test, labels=logistic.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification %age : 0.35037593984962406\n"
     ]
    }
   ],
   "source": [
    "pred_labels = []\n",
    "for i in prob_final_test:\n",
    "    i = list(i)\n",
    "    pos = i.index(max(i))\n",
    "    pred_labels.append(pos+1)\n",
    "\n",
    "print(\"Misclassification %age :\", np.count_nonzero((pred_labels - y_test_final))/y_test_final.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class : 1\n",
      "Predicted Class Probabilities: [[0.89 0.03 0.01 0.01 0.02 0.01 0.02 0.01 0.01]]\n",
      "Actual Class : 1\n"
     ]
    }
   ],
   "source": [
    "test_point_index = 5\n",
    "predicted_class = prob_logistic.predict(x_test_final[test_point_index])\n",
    "print(\"Predicted Class :\", predicted_class[0])\n",
    "print(\"Predicted Class Probabilities:\", np.round(prob_logistic.predict_proba(x_test_final[test_point_index]),2))\n",
    "print(\"Actual Class :\", y_test_final[test_point_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C = 1e-05\n",
      "CV log Loss : 1.2888112114505472\n",
      "For C = 0.0001\n",
      "CV log Loss : 1.2341552428671316\n",
      "For C = 0.001\n",
      "CV log Loss : 1.130969643092841\n",
      "For C = 0.01\n",
      "CV log Loss : 1.242584803512788\n",
      "For C = 0.1\n",
      "CV log Loss : 1.4057934721134888\n",
      "For C = 1\n",
      "CV log Loss : 1.5963262909367837\n",
      "For C = 10\n",
      "CV log Loss : 1.5961996011305433\n",
      "For C = 100\n",
      "CV log Loss : 1.5961992802457856\n"
     ]
    }
   ],
   "source": [
    "# Since we have used the loss argument as 'hinge', it will function as an **SVM Classifier**\n",
    "\n",
    "c = [10 ** x for x in range(-5, 3)]\n",
    "list_log_loss = []\n",
    "for i in c:\n",
    "    print(\"For C =\", i)\n",
    "#    svc = SVC(C=i,kernel='linear',probability=True, class_weight='balanced', random_state = 42)\n",
    "    svc = SGDClassifier(class_weight='balanced', alpha=i, penalty='l2', loss='hinge', random_state=60)\n",
    "    svc.fit(x_train_final, y_train_final)\n",
    "    prob_svc = CalibratedClassifierCV(svc, method=\"sigmoid\")\n",
    "    prob_svc.fit(x_train_final, y_train_final)\n",
    "    prob_x_cv = prob_svc.predict_proba(x_cv_final)\n",
    "    list_log_loss.append(log_loss(y_cv_final, prob_x_cv, labels=svc.classes_, eps=1e-15))\n",
    "    print(\"CV log Loss :\",log_loss(y_cv_final, prob_x_cv)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling with the best value of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For values of best alpha =  0.001\n",
      "\n",
      "Train log loss : 0.6078792833811073\n",
      "Cross Validation log loss : 1.130969643092841\n",
      "Test log loss : 1.1197654783603976\n"
     ]
    }
   ],
   "source": [
    "best_alpha = np.argmin(list_log_loss)\n",
    "svc = SGDClassifier(class_weight='balanced', alpha=alpha[best_alpha], penalty='l2', loss='hinge', random_state=60)\n",
    "svc.fit(x_train_final, y_train_final)\n",
    "prob_svc = CalibratedClassifierCV(svc, method=\"sigmoid\")\n",
    "prob_svc.fit(x_train_final, y_train_final)\n",
    "\n",
    "print('For values of best alpha = ', alpha[best_alpha])\n",
    "prob_final_train = prob_svc.predict_proba(x_train_final) \n",
    "print('\\nTrain log loss :',log_loss(y_train_final, prob_final_train, labels=svc.classes_))\n",
    "prob_final_cv = prob_svc.predict_proba(x_cv_final)\n",
    "print('Cross Validation log loss :',log_loss(y_cv_final, prob_final_cv, labels=svc.classes_))\n",
    "prob_final_test = prob_svc.predict_proba(x_test_final)\n",
    "print('Test log loss :',log_loss(y_test_final, prob_final_test, labels=svc.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification %age : 0.3518796992481203\n"
     ]
    }
   ],
   "source": [
    "pred_labels = []\n",
    "for i in prob_final_test:\n",
    "    i = list(i)\n",
    "    pos = i.index(max(i))\n",
    "    pred_labels.append(pos+1)\n",
    "\n",
    "print(\"Misclassification %age :\", np.count_nonzero((pred_labels - y_test_final))/y_test_final.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class : 1\n",
      "Predicted Class Probabilities: [[0.84 0.04 0.   0.04 0.02 0.   0.05 0.   0.01]]\n",
      "Actual Class : 1\n"
     ]
    }
   ],
   "source": [
    "test_point_index = 5\n",
    "predicted_class = prob_svc.predict(x_test_final[test_point_index])\n",
    "print(\"Predicted Class :\", predicted_class[0])\n",
    "print(\"Predicted Class Probabilities:\", np.round(prob_svc.predict_proba(x_test_final[test_point_index]),2))\n",
    "print(\"Actual Class :\", y_test_final[test_point_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for n_estimators = 100\n",
      "CV log Loss : 1.239328435179232\n",
      "for n_estimators = 200\n",
      "CV log Loss : 1.2296648304669864\n",
      "for n_estimators = 500\n",
      "CV log Loss : 1.2221892286188227\n",
      "for n_estimators = 1000\n",
      "CV log Loss : 1.2189293146494184\n",
      "for n_estimators = 2000\n",
      "CV log Loss : 1.2176029595437161\n"
     ]
    }
   ],
   "source": [
    "n_est = [100,200,500,1000,2000]\n",
    "list_log_loss = []\n",
    "for i in n_est:\n",
    "        print(\"for n_estimators =\", i)\n",
    "        rf = RandomForestClassifier(n_estimators=i, criterion='gini', max_depth=10, random_state=60, n_jobs=-1)\n",
    "        rf.fit(x_train_final, y_train_final)\n",
    "        prob_rf = CalibratedClassifierCV(rf, method=\"sigmoid\")\n",
    "        prob_rf.fit(x_train_final, y_train_final)\n",
    "        prob_cv_rf = prob_rf.predict_proba(x_cv_final)\n",
    "        list_log_loss.append(log_loss(y_cv_final, prob_cv_rf, labels=rf.classes_, eps=1e-15))\n",
    "        print(\"CV log Loss :\",log_loss(y_cv_final, prob_cv_rf)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that there isnt much difference in the log loss values of (n_estimators = 500 & max_depth = 10) and (n_estimators = 2000 & max_depth = 10), but there is a big difference in the time complexity of the two. Hence, we select the best pair to be n_estimaotrs = 500 and max_depth = 10 as it has lower time complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modellling with the best value of estimators and max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For values of best estimator =  1000\n",
      "\n",
      "Train log loss : 0.6342129238888813\n",
      "Cross Validation log loss : 1.2189293146494184\n",
      "Test log loss : 1.1526961241417986\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, criterion='gini', max_depth=10, random_state=60, n_jobs=-1)\n",
    "rf.fit(x_train_final, y_train_final)\n",
    "prob_rf = CalibratedClassifierCV(rf, method=\"sigmoid\")\n",
    "prob_rf.fit(x_train_final, y_train_final)\n",
    "\n",
    "print('For values of best estimator = ', 1000) \n",
    "prob_final_train = prob_rf.predict_proba(x_train_final)\n",
    "print('\\nTrain log loss :',log_loss(y_train_final, prob_final_train, labels=rf.classes_))\n",
    "prob_final_cv = prob_rf.predict_proba(x_cv_final)\n",
    "print('Cross Validation log loss :',log_loss(y_cv_final, prob_final_cv, labels=rf.classes_))\n",
    "prob_final_test = prob_rf.predict_proba(x_test_final)\n",
    "print('Test log loss :',log_loss(y_test_final, prob_final_test, labels=rf.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification %age : 0.37142857142857144\n"
     ]
    }
   ],
   "source": [
    "pred_labels = []\n",
    "for i in prob_final_test:\n",
    "    i = list(i)\n",
    "    pos = i.index(max(i))\n",
    "    pred_labels.append(pos+1)\n",
    "\n",
    "print(\"Misclassification %age :\", np.count_nonzero((pred_labels - y_test_final))/y_test_final.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class : 1\n",
      "Predicted Class Probabilities: [[0.5  0.06 0.02 0.24 0.05 0.04 0.07 0.01 0.01]]\n",
      "Actual Class : 1\n"
     ]
    }
   ],
   "source": [
    "test_point_index = 5\n",
    "predicted_class = prob_rf.predict(x_test_final[test_point_index])\n",
    "print(\"Predicted Class :\", predicted_class[0])\n",
    "print(\"Predicted Class Probabilities:\", np.round(prob_rf.predict_proba(x_test_final[test_point_index]),2))\n",
    "print(\"Actual Class :\", y_test_final[test_point_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The best result from all the three models was from *'Logistic Regression'*, probably because of Logistic Regression's ablility to handle large dimensional dataset better.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
